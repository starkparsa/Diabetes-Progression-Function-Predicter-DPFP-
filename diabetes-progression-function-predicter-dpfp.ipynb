{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":482,"sourceType":"datasetVersion","datasetId":228}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Problem Statement\nThe Diabetes Pedigree Function (DPF) is a tool used to assess the genetic risk of diabetes mellitus based on family history. Introduced in 1993 as part of the Diabetes Genetics Initiative, it calculates a numerical score indicating the likelihood of an individual developing diabetes. This score increases with each affected first-degree relative (parents or siblings), with higher scores indicating greater genetic predisposition. The DPF helps stratify individuals into risk categories, although it's important to remember that genetics is just one aspect of diabetes risk, alongside lifestyle and environmental factors. ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-17T13:25:56.575887Z","iopub.execute_input":"2024-06-17T13:25:56.576310Z","iopub.status.idle":"2024-06-17T13:25:56.991179Z","shell.execute_reply.started":"2024-06-17T13:25:56.576268Z","shell.execute_reply":"2024-06-17T13:25:56.989988Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pima-indians-diabetes-database/diabetes.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Visualization\nLet us first load the dataset in a  variable called 'diabetes' using pandas.","metadata":{}},{"cell_type":"code","source":"# Loading the diabetes pedigree function dataset\ndiabetes = pd.read_csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:56.993245Z","iopub.execute_input":"2024-06-17T13:25:56.993789Z","iopub.status.idle":"2024-06-17T13:25:57.013369Z","shell.execute_reply.started":"2024-06-17T13:25:56.993729Z","shell.execute_reply":"2024-06-17T13:25:57.012387Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Now let us review the contents of the dataframe using `describe()` function and shape of the dataframe using `shape` function to understand the data and start cleaning it.","metadata":{}},{"cell_type":"code","source":"diabetes.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.014682Z","iopub.execute_input":"2024-06-17T13:25:57.015061Z","iopub.status.idle":"2024-06-17T13:25:57.067810Z","shell.execute_reply.started":"2024-06-17T13:25:57.015028Z","shell.execute_reply":"2024-06-17T13:25:57.066290Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>120.894531</td>\n      <td>69.105469</td>\n      <td>20.536458</td>\n      <td>79.799479</td>\n      <td>31.992578</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>31.972618</td>\n      <td>19.355807</td>\n      <td>15.952218</td>\n      <td>115.244002</td>\n      <td>7.884160</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>62.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>27.300000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>23.000000</td>\n      <td>30.500000</td>\n      <td>32.000000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>127.250000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"diabetes.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.070335Z","iopub.execute_input":"2024-06-17T13:25:57.071246Z","iopub.status.idle":"2024-06-17T13:25:57.077095Z","shell.execute_reply.started":"2024-06-17T13:25:57.071204Z","shell.execute_reply":"2024-06-17T13:25:57.076173Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(768, 9)"},"metadata":{}}]},{"cell_type":"markdown","source":"From the above function we can see that there are 768 rows and 9 columns. Here our main focus is on the columns which are:\n   - Pregnancies\n   - Glucose\n   - Blood Pressure\n   - Skin Thickness\n   - Insulin\n   - BMI\n   - Diabetes Pedigree Function(DPF)\n   - Age\n   - Outcome\n\nIn the folloing we are going to predict Diabetes Pedigree Function(DPF) based on the other columns.","metadata":{}},{"cell_type":"markdown","source":"# Data Pre-processing\nFrom studying the description of the dataframe we can conclude few things about the data of Prima Indians Diabetes dataset they are:\n - There are many zeros present in the dataset but zeroes in `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI` don't make any sense which means they are replacements of null data.\n - We will replace zero with null using `replace()` function.","metadata":{}},{"cell_type":"code","source":"# Loading columns to change to null instead of zero\nzero_columns = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\ndiabetes[zero_columns] = diabetes[zero_columns].replace(0, np.nan)\n\ndiabetes.describe()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.078624Z","iopub.execute_input":"2024-06-17T13:25:57.079251Z","iopub.status.idle":"2024-06-17T13:25:57.122707Z","shell.execute_reply.started":"2024-06-17T13:25:57.079225Z","shell.execute_reply":"2024-06-17T13:25:57.121219Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  763.000000     733.000000     541.000000  394.000000   \nmean      3.845052  121.686763      72.405184      29.153420  155.548223   \nstd       3.369578   30.535641      12.382158      10.476982  118.775855   \nmin       0.000000   44.000000      24.000000       7.000000   14.000000   \n25%       1.000000   99.000000      64.000000      22.000000   76.250000   \n50%       3.000000  117.000000      72.000000      29.000000  125.000000   \n75%       6.000000  141.000000      80.000000      36.000000  190.000000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  757.000000                768.000000  768.000000  768.000000  \nmean    32.457464                  0.471876   33.240885    0.348958  \nstd      6.924988                  0.331329   11.760232    0.476951  \nmin     18.200000                  0.078000   21.000000    0.000000  \n25%     27.500000                  0.243750   24.000000    0.000000  \n50%     32.300000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>763.000000</td>\n      <td>733.000000</td>\n      <td>541.000000</td>\n      <td>394.000000</td>\n      <td>757.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>121.686763</td>\n      <td>72.405184</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.457464</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>30.535641</td>\n      <td>12.382158</td>\n      <td>10.476982</td>\n      <td>118.775855</td>\n      <td>6.924988</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>44.000000</td>\n      <td>24.000000</td>\n      <td>7.000000</td>\n      <td>14.000000</td>\n      <td>18.200000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>64.000000</td>\n      <td>22.000000</td>\n      <td>76.250000</td>\n      <td>27.500000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>29.000000</td>\n      <td>125.000000</td>\n      <td>32.300000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>141.000000</td>\n      <td>80.000000</td>\n      <td>36.000000</td>\n      <td>190.000000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"We can now see that the minimum values of `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI` are not zeros any more which they are the real ones and null values have been created instead of zeroes to double check it we will use `info()` to check number of non-null values.","metadata":{}},{"cell_type":"code","source":"diabetes.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.124434Z","iopub.execute_input":"2024-06-17T13:25:57.125116Z","iopub.status.idle":"2024-06-17T13:25:57.152188Z","shell.execute_reply.started":"2024-06-17T13:25:57.125078Z","shell.execute_reply":"2024-06-17T13:25:57.151164Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    int64  \n 1   Glucose                   763 non-null    float64\n 2   BloodPressure             733 non-null    float64\n 3   SkinThickness             541 non-null    float64\n 4   Insulin                   394 non-null    float64\n 5   BMI                       757 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    int64  \n 8   Outcome                   768 non-null    int64  \ndtypes: float64(6), int64(3)\nmemory usage: 54.1 KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Since there is difference in non-null values we can say we were successful in representing null values. \n\nWe will do the follwing :\n - Use simple Imputer to change null value.\n - Use median startegy because it is not sensitive to outliers.\n\nDoing this will allow us to make the prediction a bit more accurate.","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n# Simple imputer function with median strategy\nimputer = SimpleImputer(strategy = 'median')\n\n# Imputing the dataset\nimputed_diabetes = pd.DataFrame(imputer.fit_transform(diabetes), columns=diabetes.columns)\n\nimputed_diabetes.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.153476Z","iopub.execute_input":"2024-06-17T13:25:57.156042Z","iopub.status.idle":"2024-06-17T13:25:57.973712Z","shell.execute_reply.started":"2024-06-17T13:25:57.156004Z","shell.execute_reply":"2024-06-17T13:25:57.972599Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Pregnancies               768 non-null    float64\n 1   Glucose                   768 non-null    float64\n 2   BloodPressure             768 non-null    float64\n 3   SkinThickness             768 non-null    float64\n 4   Insulin                   768 non-null    float64\n 5   BMI                       768 non-null    float64\n 6   DiabetesPedigreeFunction  768 non-null    float64\n 7   Age                       768 non-null    float64\n 8   Outcome                   768 non-null    float64\ndtypes: float64(9)\nmemory usage: 54.1 KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After using simple imputer we can see that there are no null values in the dataset. Now let us divide the dataset into X and y where :\n - X = All columns except DiabetesPedigreeFunction\n - y = DiabetesPedigreeFunction","metadata":{}},{"cell_type":"code","source":"X = imputed_diabetes.drop('DiabetesPedigreeFunction',axis = 1)\ny = imputed_diabetes.DiabetesPedigreeFunction","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.975086Z","iopub.execute_input":"2024-06-17T13:25:57.975452Z","iopub.status.idle":"2024-06-17T13:25:57.980675Z","shell.execute_reply.started":"2024-06-17T13:25:57.975423Z","shell.execute_reply":"2024-06-17T13:25:57.979666Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We will now Split X and y into **X_train**, **X_test** and **y_train**, **y_test** where train values are 70% and test being 30% of original.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Splitting data\nX_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.3, random_state= 1)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.981900Z","iopub.execute_input":"2024-06-17T13:25:57.982526Z","iopub.status.idle":"2024-06-17T13:25:57.993806Z","shell.execute_reply.started":"2024-06-17T13:25:57.982499Z","shell.execute_reply":"2024-06-17T13:25:57.992838Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Fitting and Prediction\n\nWe will first use Random Forest to fit and predict values with 50 n_estimators and random_state as 1.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# RandomForestRegressor variable creation\nrfr = RandomForestRegressor(n_estimators= 50, random_state=1)\n\n# Fitting train data using RandomForestRegressor\nrfr.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:57.996382Z","iopub.execute_input":"2024-06-17T13:25:57.996698Z","iopub.status.idle":"2024-06-17T13:25:58.264801Z","shell.execute_reply.started":"2024-06-17T13:25:57.996671Z","shell.execute_reply":"2024-06-17T13:25:58.263627Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"RandomForestRegressor(n_estimators=50, random_state=1)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(n_estimators=50, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\n\n# Predicting test data\ny_pred = rfr.predict(X_test)\n\n# Mean Absolute Error\nmae_rfr = mean_absolute_error(y_test, y_pred)\nprint(\"Mean Absolute Error for Random Forest Regression:\", mae_rfr)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:58.266690Z","iopub.execute_input":"2024-06-17T13:25:58.267649Z","iopub.status.idle":"2024-06-17T13:25:58.281923Z","shell.execute_reply.started":"2024-06-17T13:25:58.267609Z","shell.execute_reply":"2024-06-17T13:25:58.280659Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Mean Absolute Error for Random Forest Regression: 0.2536424242424242\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will now use XG Boost to train and predict values with Learning rate of 0.009 and max leaves of 10.","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBRegressor\n\n# XG Boost variable creation\nxgbr = XGBRegressor(learning_rate = 0.009,max_leaves = 10)\n\n# Fitting train data using XGBRegressor\nxgbr.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:58.283147Z","iopub.execute_input":"2024-06-17T13:25:58.283446Z","iopub.status.idle":"2024-06-17T13:25:58.564130Z","shell.execute_reply.started":"2024-06-17T13:25:58.283421Z","shell.execute_reply":"2024-06-17T13:25:58.563194Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.009, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=10,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)","text/html":"<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.009, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=10,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=None, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             gamma=None, grow_policy=None, importance_type=None,\n             interaction_constraints=None, learning_rate=0.009, max_bin=None,\n             max_cat_threshold=None, max_cat_to_onehot=None,\n             max_delta_step=None, max_depth=None, max_leaves=10,\n             min_child_weight=None, missing=nan, monotone_constraints=None,\n             multi_strategy=None, n_estimators=None, n_jobs=None,\n             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = xgbr.predict(X_test)\n\nmae_xgbr = mean_absolute_error(y_test,y_pred)\nprint(\"Mean Absolute Error for XG Boost:\", mae_xgbr)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T13:25:58.565167Z","iopub.execute_input":"2024-06-17T13:25:58.565440Z","iopub.status.idle":"2024-06-17T13:25:58.578430Z","shell.execute_reply.started":"2024-06-17T13:25:58.565417Z","shell.execute_reply":"2024-06-17T13:25:58.577515Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Mean Absolute Error for XG Boost: 0.24156465896486715\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Result \n\nAfter comapring both random forest and xg boost we can say that xg boost performed well in this scenario based on the median absolute error(mae). where the mae value of xg boost is 0.24156465896486715. Therefore we will be going forward with XG Boost algorithm for this dataset and problem.","metadata":{}}]}